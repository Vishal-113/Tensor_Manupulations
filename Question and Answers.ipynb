{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeE0fJduDfwuLr7mUVhvHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishal-113/Tensor_Manupulations/blob/main/Question%20and%20Answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1. What patterns do you see in accuracy curves?\n",
        "\t*Steady Training Accuracy Growth: The model continuously improves its ability to classify data correctly during training.\n",
        "\t*Validation Accuracy Follows Initially: At the start, validation accuracy rises alongside training accuracy as the model learns general patterns.\n",
        "\t*Possible Fluctuations: At some point, validation accuracy might stop improving or start oscillating.\n",
        "\t*Signs of Overfitting: If training accuracy keeps improving while validation accuracy declines, the model is memorizing training data instead of generalizing.\n",
        "\t*Underfitting Issues: If validation accuracy remains low even after multiple epochs, the model might be too simple for the problem.\n",
        "\n",
        "\n",
        "2. How can TensorBoard help spot overfitting?\n",
        "\t*Loss Trends Analysis: If training loss keeps decreasing while validation loss increases, it signals overfitting.\n",
        "\t*Accuracy Gap Monitoring: A gap between training and validation accuracy suggests the model is struggling to generalize.\n",
        "\t*Histogram Visualization: Examining weight histograms in TensorBoard helps detect extreme values, which often indicate overfitting.\n",
        "\t*Learning Rate Insights: By tracking gradient updates, TensorBoard can show if the model is learning too aggressively or too slowly.\n",
        "\t*Early Stopping Decision Making: If validation metrics start declining, TensorBoard helps decide when to stop training.\n",
        "\n",
        "\n",
        "3. What happens when you increase the number of epochs?\n",
        "\t*Improved Learning Initially: More epochs allow the model to refine its understanding and improve accuracy.\n",
        "\t*Risk of Overfitting: After a certain point, training accuracy may continue improving, but validation accuracy might drop.\n",
        "\t*Longer Training Time: Increasing epochs requires more computation, which could slow down training or waste resources.\n",
        "\t*Potential Validation Loss Increase: If trained too long, the model starts focusing too much on training examples, losing generalization ability.\n",
        "\t*Best Practice: (Early Stopping) Implementing early stopping prevents unnecessary training once the model stops improving.\n"
      ],
      "metadata": {
        "id": "OOJd8Y8vfNQO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}